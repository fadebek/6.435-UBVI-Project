{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zobay.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV0eO5N52Rz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb10050-8ddf-49e0-aec7-9ef077245f10"
      },
      "source": [
        "!pip install scipy --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e8/43ffca541d2f208d516296950b25fe1084b35c2881f4d444c1346ca75815/scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4MB 144kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-Up5DQW2dVU"
      },
      "source": [
        "from functools import partial\n",
        "from re import A\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import gamma, softmax\n",
        "from scipy.linalg import sqrtm\n",
        "import scipy.stats\n",
        "\n",
        "PI = 3.1415926535897932384626\n",
        "E = 2.718281828459045\n",
        "EPSILON = 0.000001\n",
        "\n",
        "omega = lambda k: 2 * PI**((k-1)/2) / gamma((k-1)/2)\n",
        "c = lambda k: 0.39894228040143267793**k\n",
        "\n",
        "# utils\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "def multidet(M):\n",
        "  # Determinant of multidimensional matrix\n",
        "  dm = np.zeros(M.shape[0])\n",
        "  for _ in range(len(dm)):\n",
        "    dm[_] = np.linalg.det(M[_])\n",
        "  return dm[np.newaxis].T\n",
        "\n",
        "# 90% sure this can be done using broadcasting:\n",
        "def multimult(A, B):\n",
        "  # \"Broadcast\" multiplication of matrices with vector\n",
        "  dm = np.zeros(A.shape + B.shape)\n",
        "  for _ in range(len(dm)):\n",
        "    dm[_] = A[_] * B\n",
        "  return dm\n",
        "\n",
        "def gaussianExpectation(mu, cov, fn, n_samples=1000, presamples=None):\n",
        "  if type(presamples) == type(None):\n",
        "    samples = np.random.multivariate_normal(mu, cov, n_samples)\n",
        "  else:\n",
        "    samples = presamples\n",
        "  return np.mean(np.apply_along_axis(fn, 1, samples), axis=0)\n",
        "\n",
        "def mvNormpdf(x, mu, cov):\n",
        "  k = mu.shape[0]\n",
        "  return 1/((2*np.pi)**(k/2)*(np.linalg.det(cov)**0.5))* np.exp(-0.5 * ((x-mu).T @ (np.linalg.pinv(cov)) @ (x-mu)).sum())\n",
        "\n",
        "def logRatio(mu1, mu2, sig1, sig2, w1, w2):\n",
        "  return np.log(1 + (w2 * mvNormpdf(x, mu2, sig2))/(w1 * mvNormpdf(x, mu1, sig1)))\n",
        "\n",
        "def pairwiseObjective(mu1, mu2, sig1, sig2, w1, w2):\n",
        "  return -w1 * gaussianExpectation() - w2 * gaussianExpectation()\n",
        "\n",
        "class Param:\n",
        "  def __init__(self):\n",
        "    self.m_prev = 0\n",
        "    self.v_prev = 0\n",
        "  \n",
        "class VGMM:\n",
        "    def __init__(self, k=1, d=1):\n",
        "        \"\"\"We have a few parameters:\n",
        "        sigma_0 = base sigma\n",
        "        lambda_i (i \\in range(1, k+1)) = sigma multiple\n",
        "        w_i (i \\in range(1, k+1)) = weight\n",
        "        mu_i = mean\n",
        "        \"\"\"\n",
        "\n",
        "        self.sigma_0 = np.eye(d)\n",
        "        self.lambdas = np.random.rand(k, 1)\n",
        "        self.Ws = np.random.rand(k, 1)\n",
        "        self.ws = softmax(self.Ws)\n",
        "        self.mus = np.random.rand(k, d)\n",
        "\n",
        "        self.k = k\n",
        "        self.d = d\n",
        "\n",
        "        self.eta = 0.03 # learning rate\n",
        "\n",
        "        #adam\n",
        "        self.beta_1 = 0.9\n",
        "        self.beta_2 = 0.999\n",
        "        self.epsilon = 10**(-8)\n",
        "        self.m_prev = 0\n",
        "        self.v_prev = 0\n",
        "        self.adamparams = {}\n",
        "\n",
        "        self.n_samples = 1000\n",
        "        self.cgd = False\n",
        "\n",
        "        self.whist = []\n",
        "        self.lambdahist = [[] for i in range(k)]\n",
        "        self.lambdaghist = [[] for i in range(k)]\n",
        "        self.muhist = [[] for i in range(k)]\n",
        "        self.h = []\n",
        "\n",
        "    def get_grad(self, grad, params=None):\n",
        "      return self.adam(grad, params=params)\n",
        "    \n",
        "    def adam(self, grad, params):\n",
        "      if params['id'] not in self.adamparams:\n",
        "        self.adamparams[params['id']] = Param()\n",
        "      s = self.adamparams[params['id']]\n",
        "\n",
        "      s.m_current = self.beta_1 * s.m_prev + (1 - self.beta_1) * grad\n",
        "      s.v_current = self.beta_2 * s.v_prev + (1 - self.beta_2) * grad**2\n",
        "      s.m_norm = s.m_current/(1 - self.beta_1**(params['t']+1))\n",
        "      s.v_norm = s.v_current/(1 - self.beta_2**(params['t']+1))\n",
        "\n",
        "      s.m_prev = s.m_current * 1.0\n",
        "      s.v_prev = s.v_current * 1.0\n",
        "\n",
        "      if params['id'] == 'lambda':\n",
        "        self.h.append(self.eta * s.m_norm/((s.v_norm**0.5) + self.epsilon))\n",
        "      return self.eta * s.m_norm/((s.v_norm**0.5) + self.epsilon)\n",
        "\n",
        "    def setTarget(self, dist):\n",
        "       # idea: compute sigma_0 based on ELBO\n",
        "       dist1 = scipy.stats.norm(-1, 0.5).pdf\n",
        "       dist2 = scipy.stats.norm(1, 2).pdf\n",
        "       self.targetpdf = lambda x: 0.3 * dist1(x) + 0.7 * dist2(x)\n",
        "       self.logp = lambda x: np.log(self.targetpdf(x)) if np.log(self.targetpdf(x)) > -100 else -100\n",
        "\n",
        "    def coordinateDescent(self, rounds=500, entropyRounds=1, energyRounds=1):\n",
        "        # TODO: allow \"change < epsilon\" flag\n",
        "        maxrounds = rounds\n",
        "        round = 0\n",
        "        \n",
        "        while True:\n",
        "            self.round = round\n",
        "            if round == maxrounds:\n",
        "                break\n",
        "            \n",
        "            #print(self.mus.shape)\n",
        "            if round % 10 == 0:\n",
        "              print(\"round\", round)\n",
        "              pass\n",
        "            for i in range(self.ws.shape[0]):\n",
        "                self.entropyDescent(rounds=entropyRounds, param=(\"w\", i))\n",
        "                self.energyDescent(rounds=energyRounds, param=(\"w\", i))\n",
        "                self.ws = softmax(self.Ws)\n",
        "            for i in range(self.lambdas.shape[0]):\n",
        "                self.entropyDescent(rounds=entropyRounds, param=(\"lambda\", i))\n",
        "                self.energyDescent(rounds=energyRounds, param=(\"lambda\", i))\n",
        "                pass\n",
        "            for i in range(self.mus.shape[0]):\n",
        "                self.entropyDescent(rounds=entropyRounds, param=(\"mu\", i))\n",
        "                self.energyDescent(rounds=energyRounds, param=(\"mu\", i))\n",
        "\n",
        "            round += 1\n",
        "\n",
        "    def entropyDescent(self, rounds=1, param=None):\n",
        "        \n",
        "        # maximize entropy wrt params \n",
        "        self.ws = softmax(self.Ws)\n",
        "        for round in range(rounds):\n",
        "            # update wrt individual entropies\n",
        "\n",
        "            # det of arrays within array, see https://stackoverflow.com/questions/13393733/determinant-of-multidimensional-array for optimization options\n",
        "            if round % 10 == 0:\n",
        "              # print(round, multimult(self.lambdas, self.sigma_0))\n",
        "              # print(round, self.mus)\n",
        "              pass\n",
        "            wGrads = -(np.log(self.ws)+1) + 1/2 * np.log(multidet(2*PI*E*multimult(self.lambdas**2, self.sigma_0))) * self.ws * (1 - self.ws)\n",
        "            lambdaGrads = self.ws * self.d/(self.lambdas + EPSILON)\n",
        "\n",
        "            var, ind = param\n",
        "            # only update one variable at a time\n",
        "            if var == \"w\" or not self.cgd:\n",
        "                # mask = np.zeros(self.Ws.shape)\n",
        "                # mask[ind] = np.ones(self.Ws[ind].shape)\n",
        "                self.Ws += self.get_grad(wGrads, params={'t':self.round, 'id':'node-W'})\n",
        "            \n",
        "            if var == \"lambda\" or not self.cgd:\n",
        "                # mask = np.zeros(self.lambdas.shape)\n",
        "                # mask[ind] = np.ones(self.lambdas[ind].shape)\n",
        "                self.lambdas += self.get_grad(lambdaGrads, params={'t':self.round, 'id':'node-lambdas'})\n",
        "\n",
        "            # self.whist.append((len(self.whist), self.ws[0][0]))\n",
        "            self.muhist[ind].append(1.0 * self.mus[ind])\n",
        "            self.lambdahist[ind].append(1.0 * self.lambdas[ind])\n",
        "            self.lambdaghist[ind].append(1.0 * lambdaGrads[ind])\n",
        "\n",
        "            # update wrt pairwise entropies\n",
        "            Q1SAMPLES = np.random.multivariate_normal(self.mus[ind], self.lambdas[ind]**2 * self.sigma_0, self.n_samples)\n",
        "            self.Q1SAMPLES = Q1SAMPLES\n",
        "            for j in range(self.k):\n",
        "                if j != ind:\n",
        "                    w1, w2 = self.ws[ind], self.ws[j]\n",
        "                    sig1, sig2 = self.lambdas[ind]**2 * self.sigma_0, self.lambdas[j]**2 * self.sigma_0\n",
        "                    sig1inv = np.linalg.inv(self.sigma_0 * self.lambdas[ind]**2)\n",
        "                    sig2inv = np.linalg.inv(self.sigma_0 * self.lambdas[j]**2)\n",
        "                    mu1, mu2 = self.mus[ind], self.mus[j]\n",
        "\n",
        "                    if var == \"w\" or not self.cgd:\n",
        "                      wfn1 = lambda x: np.log(1+(w2*mvNormpdf(x, mu2, sig2)/(w1 * mvNormpdf(x, mu1, sig1)))) + 1/(1+(w2*mvNormpdf(x, mu2, sig2)/(EPSILON + w1 * mvNormpdf(x, mu1, sig1)))) * (w2 * mvNormpdf(x, mu2, sig2)/(EPSILON + mvNormpdf(x, mu1, sig1))) * (-1/(EPSILON + w1))\n",
        "                      wfn2 = lambda x: 1/(1 + (w1 * mvNormpdf(x, mu1, sig1))/(w2 * mvNormpdf(x, mu2, sig2))) * 1/(EPSILON + w2)\n",
        "                      self.Ws[ind] += self.get_grad(-gaussianExpectation(None, None, wfn1, presamples=Q1SAMPLES) - w2 * gaussianExpectation(None, None, wfn2, presamples=Q1SAMPLES) * w1 * (1 - w1), params={'t':self.round, 'id':'pair-'+str(ind)+','+str(j)+'-W'})\n",
        "\n",
        "                    if var == \"mu\" or not self.cgd:\n",
        "                      omega1 = lambda x: 1/(1+(w2*mvNormpdf(x, mu2, sig2)/(EPSILON + w1 * mvNormpdf(x, mu1, sig1)))) * (w2 * mvNormpdf(x, mu2, sig2)/(EPSILON + mvNormpdf(x, mu1, sig1))) * (-1/(EPSILON + mvNormpdf(x, mu1, sig1)**2)) * mvNormpdf(x, mu1, sig1) * -sig1inv @ (x - mu1[np.newaxis])\n",
        "                      mufn1 = lambda x: -sig1inv @ (x - mu1[np.newaxis]) * np.log(1+(w2*mvNormpdf(x, mu2, sig2)/(w1 * mvNormpdf(x, mu1, sig1)))) + omega1(x)\n",
        "                      mufn2 = lambda x: mvNormpdf(x, mu2, sig2) * 1/(1 + (w1 * mvNormpdf(x, mu1, sig1))/(w2 * mvNormpdf(x, mu2, sig2))) * w1/(EPSILON + w2 * mvNormpdf(x, mu2, sig2)) * -sig1inv @ (x - mu1[np.newaxis])\n",
        "                      self.mus[ind] += self.get_grad(np.squeeze((-w1 * gaussianExpectation(None, None, mufn1, presamples=Q1SAMPLES) - w2 * gaussianExpectation(None, None, mufn2, presamples=Q1SAMPLES)), axis=-1), params={'t':self.round, 'id':'pair-'+str(ind)+','+str(j)+'-mu'})\n",
        "                      \n",
        "                    if var == \"lambda\" or not self.cgd:\n",
        "                      omega1 = lambda x: 1/(1+(w2*mvNormpdf(x, mu2, sig2)/(EPSILON + w1 * mvNormpdf(x, mu1, sig1)))) * (w2 * mvNormpdf(x, mu2, sig2)/(EPSILON + mvNormpdf(x, mu1, sig1))) * (-1/(EPSILON + mvNormpdf(x, mu1, sig1)**2)) * mvNormpdf(x, mu1, sig1) * (sig1inv - sig1inv @ (x - mu1[np.newaxis]) @ (x - mu1[np.newaxis]).T @ sig1inv) @ (self.lambdas[ind] * self.sigma_0)\n",
        "                      lambdafn1 = lambda x: (sig1inv - sig1inv @ (x - mu1[np.newaxis]) @ (x - mu1[np.newaxis]).T @ sig1inv) @ (self.lambdas[ind] * self.sigma_0) * np.log(1+(w2*mvNormpdf(x, mu2, sig2)/(w1 * mvNormpdf(x, mu1, sig1)))) + omega1(x)\n",
        "                      lambdafn2 = lambda x: mvNormpdf(x, mu2, sig2) * 1/(1 + (w1 * mvNormpdf(x, mu1, sig1))/(w2 * mvNormpdf(x, mu2, sig2))) * w1/(EPSILON + w2 * mvNormpdf(x, mu2, sig2)) * (sig1inv - sig1inv @ (x - mu1[np.newaxis]) @ (x - mu1[np.newaxis]).T @ sig1inv) @ (self.lambdas[ind] * self.sigma_0)\n",
        "                      self.lambdas[ind] += self.get_grad(-w1 * gaussianExpectation(None, None, lambdafn1, presamples=Q1SAMPLES)[0][0] - w2 * gaussianExpectation(None, None, lambdafn2, presamples=Q1SAMPLES)[0][0], params={'t':self.round, 'id':'pair-'+str(ind)+','+str(j)+'-lambda'})\n",
        "\n",
        "    def energyDescent(self, rounds=1, param=\"dummy variable\"):\n",
        "        # minimize energy $-\\int q \\log p$ wrt params\n",
        "        self.ws = softmax(self.Ws)\n",
        "\n",
        "        for round in range(rounds):\n",
        "            for i in range(self.mus.shape[0]):\n",
        "                mu = self.mus[i].T\n",
        "                siginv = np.linalg.inv(self.sigma_0 * self.lambdas[i]**2)\n",
        "                sig = self.sigma_0 * self.lambdas[i]** 2\n",
        "                w = self.ws[i]\n",
        "\n",
        "                mufn = lambda x: self.logp(x) * siginv @ (x - mu[np.newaxis])\n",
        "                lambdafn = lambda x: self.logp(x) * -0.5 * (siginv - siginv @ (x - mu[np.newaxis]) @ (x - mu[np.newaxis]).T @ siginv) @ (2 * self.lambdas[i] * self.sigma_0)\n",
        "\n",
        "                self.mus[i] -= self.get_grad(-1 * np.squeeze(self.ws[i] * gaussianExpectation(mu, sig, mufn), axis=-1), params={'t':self.round, 'id':'energy-mus'}) * 1.1\n",
        "                self.lambdas[i] -= self.get_grad(-1 * self.ws[i] * gaussianExpectation(mu, sig, lambdafn)[0][0], params={'t':self.round, 'id':'energy-lambdas'}) # expectation should be diagonal matrix\n",
        "                self.Ws -= self.get_grad(-1 * gaussianExpectation(mu, sig, self.logp) * w * (1 - w), params={'t':self.round, 'id':'energy-W'})\n",
        "\n",
        "                # self.lambdahist.append((len(self.lambdahist), self.lambdas[0][0]))\n",
        "                self.muhist[i].append(1.0 * self.mus[i])\n",
        "                self.lambdahist[i].append(1.0 * self.lambdas[i])\n",
        "    \n",
        "    def gradHmu(self, ind):\n",
        "      z = lambda i,j: mvNormpdf(self.mus[i], self.mus[j], (self.lambdas[i]**2+self.lambdas[j]**2)*self.sigma_0)\n",
        "\n",
        "      grad = 0\n",
        "      for i in range(self.k):\n",
        "        if i != ind:\n",
        "          S += - self.ws[i] * 1/(np.sum(np.array([self.ws[j] * z(i,j) for j in range(self.k)]))) * self.ws[ind] * z(i, ind) * np.linalg.inv(self.sigma_0 * self.lambdas[ind]**2) @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis])\n",
        "        if i == ind:\n",
        "          f = - self.ws[k] * 1/(np.sum(np.array([self.ws[j] * z(i,j) for j in range(self.k)])))\n",
        "          for j in range(self.k):\n",
        "            if j != ind:\n",
        "              S += f * self.ws[j] * z(i,j) * np.linalg.inv(self.sigma_0 * self.lambdas[i]**2) @ (self.mus[j][np.newaxis] - self.mus[i][np.newaxis])\n",
        "            if j == ind:\n",
        "              S += f * self.ws[j] * z(i,j) * -0.5 * np.log(np.linalg.det(2*self.lambdas[i]*self.sigma_0))\n",
        "      return S\n",
        "    \n",
        "    def gradHsig(self, ind):\n",
        "      z = lambda i,j: mvNormpdf(self.mus[i], self.mus[j], (self.lambdas[i]**2+self.lambdas[j]**2)*self.sigma_0)\n",
        "\n",
        "      grad = 0\n",
        "      for i in range(self.k):\n",
        "        if i != ind:\n",
        "          siginv = np.linalg.inv(self.sigma_0 * (self.lambdas[i]**2+self.lambdas[ind]**2))\n",
        "          S += - self.ws[i] * 1/(np.sum(np.array([self.ws[j] * z(i,j) for j in range(self.k)]))) * self.ws[ind] * z(i, ind) * 0.5 * (siginv - siginv @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]) @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]).T @ siginv)\n",
        "        if i == ind:\n",
        "          f = - self.ws[k] * 1/(np.sum(np.array([self.ws[j] * z(i,j) for j in range(self.k)])))\n",
        "          for j in range(self.k):\n",
        "            if j != ind:\n",
        "              siginv = np.linalg.inv(self.sigma_0 * (self.lambdas[i]**2+self.lambdas[j]**2))\n",
        "              S += f * self.ws[j] * z(i, j)* 0.5 * (siginv - siginv @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]) @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]).T @ siginv)\n",
        "            if j == ind:\n",
        "              S += f * self.ws[j] * z(i, j) * (siginv - siginv @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]) @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]).T @ siginv)\n",
        "      return S\n",
        "\n",
        "    def gradHsig(self, ind):\n",
        "      z = lambda i,j: mvNormpdf(self.mus[i], self.mus[j], (self.lambdas[i]**2+self.lambdas[j]**2)*self.sigma_0)\n",
        "\n",
        "      grad = 0\n",
        "      for i in range(self.k):\n",
        "        if i != ind:\n",
        "          siginv = np.linalg.inv(self.sigma_0 * (self.lambdas[i]**2+self.lambdas[ind]**2))\n",
        "          S += - self.ws[i] * 1/(np.sum(np.array([self.ws[j] * z(i,j) for j in range(self.k)]))) * self.ws[ind] * z(i, ind) * 0.5 * (siginv - siginv @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]) @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]).T @ siginv)\n",
        "        if i == ind:\n",
        "          f = - self.ws[k] * 1/(np.sum(np.array([self.ws[j] * z(i,j) for j in range(self.k)])))\n",
        "          for j in range(self.k):\n",
        "            if j != ind:\n",
        "              siginv = np.linalg.inv(self.sigma_0 * (self.lambdas[i]**2+self.lambdas[j]**2))\n",
        "              S += f * self.ws[j] * z(i, j)* 0.5 * (siginv - siginv @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]) @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]).T @ siginv)\n",
        "            if j == ind:\n",
        "              S += f * self.ws[j] * z(i, j) * (siginv - siginv @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]) @ (self.mus[i][np.newaxis] - self.mus[ind][np.newaxis]).T @ siginv)\n",
        "      return S \n",
        "    \n",
        "    # print results\n",
        "    def printout(self, plot=False):\n",
        "        print(\"weights\", self.ws)\n",
        "        print(\"mus\", self.mus)\n",
        "        print(\"sigma_0\", self.sigma_0)\n",
        "        print(\"lambdas\", self.lambdas)\n",
        "\n",
        "        if plot:\n",
        "            if self.d > 2:\n",
        "                raise ValueError(\"Dimensionality is too large for a plot of the resultant mixture.\")\n",
        "\n",
        "            clustersamples = np.random.multinomial(300, self.ws, size=1)\n",
        "\n",
        "            data = np.array([])\n",
        "            for i in range(len(clustersamples)):\n",
        "                data = np.append(data, np.random.multivariate_normal(self.mus[i], self.lambdas[i] * self.sigma_0, clustersamples[i]))\n",
        "\n",
        "            plt.hist(data, density=True)\n",
        "            plt.show()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9TRSz1j2owY",
        "outputId": "a270270a-1f84-47db-9841-cd99bbdb7b60"
      },
      "source": [
        "vgmm = VGMM(k=1, d=1)\n",
        "\n",
        "print(vgmm.ws)\n",
        "print(vgmm.mus)\n",
        "print(vgmm.lambdas)\n",
        "print(vgmm.sigma_0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]]\n",
            "[[0.87288977]]\n",
            "[[0.80488851]]\n",
            "[[1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSOeuen12rSI"
      },
      "source": [
        "vgmm.setTarget(0) # hardcoded the target distribution, normally you'd pass a pdf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMOXUlLgzITl"
      },
      "source": [
        "vgmm.mus[0][0] = 2.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzwQOH-I2zZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8cd4b0b-8560-41fc-e1f1-620fb17df58e"
      },
      "source": [
        "vgmm.coordinateDescent(rounds=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round 0\n",
            "round 10\n",
            "round 20\n",
            "round 30\n",
            "round 40\n",
            "round 50\n",
            "round 60\n",
            "round 70\n",
            "round 80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:195: RuntimeWarning: overflow encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:195: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:201: RuntimeWarning: overflow encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:201: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:207: RuntimeWarning: overflow encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:207: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "round 90\n",
            "round 100\n",
            "round 110\n",
            "round 120\n",
            "round 130\n",
            "round 140\n",
            "round 150\n",
            "round 160\n",
            "round 170\n",
            "round 180\n",
            "round 190\n",
            "round 200\n",
            "round 210\n",
            "round 220\n",
            "round 230\n",
            "round 240\n",
            "round 250\n",
            "round 260\n",
            "round 270\n",
            "round 280\n",
            "round 290\n",
            "round 300\n",
            "round 310\n",
            "round 320\n",
            "round 330\n",
            "round 340\n",
            "round 350\n",
            "round 360\n",
            "round 370\n",
            "round 380\n",
            "round 390\n",
            "round 400\n",
            "round 410\n",
            "round 420\n",
            "round 430\n",
            "round 440\n",
            "round 450\n",
            "round 460\n",
            "round 470\n",
            "round 480\n",
            "round 490\n",
            "round 500\n",
            "round 510\n",
            "round 520\n",
            "round 530\n",
            "round 540\n",
            "round 550\n",
            "round 560\n",
            "round 570\n",
            "round 580\n",
            "round 590\n",
            "round 600\n",
            "round 610\n",
            "round 620\n",
            "round 630\n",
            "round 640\n",
            "round 650\n",
            "round 660\n",
            "round 670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVbX1qvK0qt3"
      },
      "source": [
        "plt.plot([i for i in vgmm.muhist[0]], label='line 1')\n",
        "plt.plot([i for i in vgmm.lambdahist[1]], label='line 1')\n",
        "#plt.plot([i for i in vgmm.lambdahist[0]])\n",
        "#plt.plot([i for i in vgmm.lambdaghist[0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MdNNTmGbxWr"
      },
      "source": [
        "vgmm.printout(plot=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pbjg573OG4"
      },
      "source": [
        "c = np.array(vgmm.mus)\n",
        "rv = multivariate_normal(c, vgmm.lambdas[0]**2 * vgmm.sigma_0)\n",
        "x = np.random.uniform(-5, 5, 5000)\n",
        "y = rv.pdf(x)\n",
        "z = vgmm.targetpdf(x)\n",
        "plt.scatter(x, z, s=10) # target\n",
        "plt.scatter(x, y, s=2) # vgmm\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q52qIBgs3WS5"
      },
      "source": [
        "vgmm.mus = np.array([vgmm.mus])\n",
        "vgmm.mus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkL4_h_c3gT_"
      },
      "source": [
        "vgmm.lambdas = np.array([[10.0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emxpIlbfOysO"
      },
      "source": [
        "fn = lambda x: x\n",
        "gaussianExpectation(np.array([[2],[1]]), np.eye(2), fn, n_samples=50000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsUKCaLDO_-F"
      },
      "source": [
        "vgmm.v_current"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s54OOBwRVrPq"
      },
      "source": [
        "plt.plot([i for i in vgmm.lambdaghist[0]])\n",
        "plt.plot([i for i in vgmm.lambdahist[0]])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx0R_wllaHsq"
      },
      "source": [
        "plt.plot([i[0][0] for i in vgmm.h])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xK22FvbshM"
      },
      "source": [
        "[i for i in vgmm.lambdahist[0]][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KNjgZEum5QV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}